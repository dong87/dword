---
title: "Vignette of dword"
author: "Dong Leiming"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


## install depended packages

```{r}
install.packages("tidyverse", "stringi", "koRpus", "wordcloud2", "quanteda", "htmlwidgets")
```

## create folders

```{r}
gen_dir()
```

## Mendeley setting

You'd better to set your Mendelely following this image.

![](../img/mendeley.png)

Mendelely will correct you file names automatically.

## Transfer pdfs to plain txt

```{r}
filenames <- "D:/R/Mendeley_PDF/Nature Genetics/FILENAME.pdf"
pdf2text_path <- "PATH/pdftotext.exe" ## space in the path is not allowed
pdf_2_txt(filenames, pdf2text_path)
```

## build database

```{r}
db_sci <- list(dest = "PATH/Mendeley_PDF/", myfiles = NULL, sents = NULL) # build a empty list comprising 3 elements. Assign path of the files saved by mendeley 
db_sci$myfiles <- db_sci$dest %>% all_pdf # save all the pdf file names in this element

# pdf 2 txt
pdf2text_path <- "PATH/pdftotext.exe"
pdf_2_txt(db_sci$myfiles, pdf2text_path)

db_sci$sents <- db_sci$dest %>% db_txt %>% db_sent # processing the txt transfered from pdf files and spliting into single sentences
db_sci$sents <- db_sci$sents %>% gsub("`", "'", .) %>% gsub(" {2,10}", " ", .) %>% gsub("\\[|\\]|#", "", .) # repalce some special char and usless content
save(db_sci, file = "PATH/db_sci.rdata") # save database to local
```

## extract sentences /w 3 examples

```{r}
### 尾部随机
word <- "facilit"; nf <- dsents(words = paste0("\\b", word, "\\w*"), sents = db_sci$sents, output = word, rm_pattern = "")
### 后词固定+替换
word <- "estimates"; nf <- dsents(words = paste0("\\w*", word), sents = db_sci$sents, output = word, rm_pattern = word)
### 前词固定+替换
word <- "highly"; nf <- dsents(words = paste0(word, " \\w*ed"), sents = db_sci$sents, output = word, 
  rm_pattern = paste0(word, " "))
```

## extract word

If you'd like to use this function, you have to download [TreeTagger](http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/data/tree-tagger-windows-3.2.1.zip) first, released into a folder without space.

```{r}
txts <- dwords(db_sci$sents, path_TreeTagger="PATH/TreeTagger", "outname")
```

## word frequency

```{r}
word_freq(db_sci$sents, filepath = "PATH/word_freq.csv")
```

